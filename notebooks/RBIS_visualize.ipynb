{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "import socket\n",
    "import json\n",
    "import zipfile\n",
    "import io\n",
    "import math\n",
    "import shutil\n",
    "import pprint\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import fiona\n",
    "import h5py\n",
    "import re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gdal\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "\n",
    "%matplotlib widget\n",
    "#import earthpy.Spatial as es\n",
    "\n",
    "# To read KML files with geopandas, we will need to enable KML support in fiona (disabled by default)\n",
    "fiona.drvsupport.supported_drivers['LIBKML'] = 'rw'\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from shapely.geometry.polygon import orient\n",
    "from statistics import mean\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# File name format: ATL06_[yyyymmdd][hhmmss]_[RGTccss]_[vvv_rr].h5\n",
    "\n",
    "#NOTE: Need to simplify this function\n",
    "def time_from_fname(fname):\n",
    "    \"\"\" IS2 fname -> datatime object. \"\"\"\n",
    "    t = fname.split('_')[1]\n",
    "    y, m , d, h, mn, s = t[:4], t[4:6], t[6:8], t[8:10], t[10:12], t[12:14]\n",
    "    time = dt.datetime(int(y), int(m), int(d), int(h), int(mn), int(s))\n",
    "    return time\n",
    "\n",
    "\n",
    "def segment_from_fname(fname):\n",
    "    \"\"\" IS2 fname -> segment number. \"\"\"\n",
    "    s = fname.split('_')[2]\n",
    "    return int(s[-2:])\n",
    "\n",
    "\n",
    "def select_files(files, segments=[10,11,12], t1=(2019,1,1), t2=(2019,2,1)):\n",
    "    t1 = dt.datetime(*t1)\n",
    "    t2 = dt.datetime(*t2)\n",
    "    files_out = []\n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "        time = time_from_fname(fname)\n",
    "        segment = segment_from_fname(fname)\n",
    "        if t1 <= time <= t2 and segment in segments:\n",
    "            files_out.append(f)\n",
    "    return files_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from astropy.time import Time\n",
    "\n",
    "def gps2dyr(time):\n",
    "    \"\"\" Converte GPS time to decimal years. \"\"\"\n",
    "    return Time(time, format='gps').decimalyear\n",
    "\n",
    "\n",
    "def track_type(time, lat, tmax=1):\n",
    "    \"\"\"\n",
    "    Separate tracks into ascending and descending.\n",
    "    \n",
    "    Defines tracks as segments with time breaks > tmax,\n",
    "    and tests whether lat increases or decreases w/time.\n",
    "    \"\"\"\n",
    "    tracks = np.zeros(lat.shape)  # generate track segment\n",
    "    tracks[0:np.argmax(np.abs(lat))] = 1  # set values for segment\n",
    "    i_asc = np.zeros(tracks.shape, dtype=bool)  # output index array\n",
    "\n",
    "    # Loop trough individual secments\n",
    "    for track in np.unique(tracks):\n",
    "    \n",
    "        i_track, = np.where(track == tracks)  # get all pts from seg\n",
    "    \n",
    "        if len(i_track) < 2: continue\n",
    "    \n",
    "        # Test if lat increases (asc) or decreases (des) w/time\n",
    "        i_min = time[i_track].argmin()\n",
    "        i_max = time[i_track].argmax()\n",
    "        lat_diff = lat[i_track][i_max] - lat[i_track][i_min]\n",
    "    \n",
    "        # Determine track type\n",
    "        if lat_diff > 0:  i_asc[i_track] = True\n",
    "    \n",
    "    return i_asc, np.invert(i_asc)  # index vectors\n",
    "\n",
    "\n",
    "def transform_coord(proj1, proj2, x, y):\n",
    "    \"\"\"\n",
    "    Transform coordinates from proj1 to proj2 (EPSG num).\n",
    "\n",
    "    Example EPSG projs:\n",
    "        Geodetic (lon/lat): 4326\n",
    "        Polar Stereo AnIS (x/y): 3031\n",
    "        Polar Stereo GrIS (x/y): 3413\n",
    "    \"\"\"\n",
    "    # Set full EPSG projection strings\n",
    "    proj1 = pyproj.Proj(\"+init=EPSG:\"+str(proj1))\n",
    "    proj2 = pyproj.Proj(\"+init=EPSG:\"+str(proj2))\n",
    "    return pyproj.transform(proj1, proj2, x, y)  # convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def read_atl06(fname, bbox=None):\n",
    "    \"\"\" \n",
    "    Read 1 ATL06 file and output 6 reduced files. \n",
    "    \n",
    "    Extract variables of interest and separate the ATL06 file \n",
    "    into each beam (ground track) and ascending/descending orbits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Each beam is a group\n",
    "    group = ['/gt1l', '/gt1r', '/gt2l', '/gt2r', '/gt3l', '/gt3r']\n",
    "\n",
    "    # Loop trough beams\n",
    "    for k,g in enumerate(group):\n",
    "    \n",
    "        #-----------------------------------#\n",
    "        # 1) Read in data for a single beam #\n",
    "        #-----------------------------------#\n",
    "    \n",
    "        # Load variables into memory (more can be added!)\n",
    "        with h5py.File(fname, 'r') as fi:\n",
    "            lat = fi[g+'/land_ice_segments/latitude'][:]\n",
    "            lon = fi[g+'/land_ice_segments/longitude'][:]\n",
    "            h_li = fi[g+'/land_ice_segments/h_li'][:]\n",
    "            s_li = fi[g+'/land_ice_segments/h_li_sigma'][:]\n",
    "            t_dt = fi[g+'/land_ice_segments/delta_time'][:]\n",
    "            q_flag = fi[g+'/land_ice_segments/atl06_quality_summary'][:]\n",
    "            s_fg = fi[g+'/land_ice_segments/fit_statistics/signal_selection_source'][:]\n",
    "            snr = fi[g+'/land_ice_segments/fit_statistics/snr_significance'][:]\n",
    "            h_rb = fi[g+'/land_ice_segments/fit_statistics/h_robust_sprd'][:]\n",
    "            dac = fi[g+'/land_ice_segments/geophysical/dac'][:]\n",
    "            f_sn = fi[g+'/land_ice_segments/geophysical/bsnow_conf'][:]\n",
    "            dh_fit_dx = fi[g+'/land_ice_segments/fit_statistics/dh_fit_dx'][:]\n",
    "            tide_earth = fi[g+'/land_ice_segments/geophysical/tide_earth'][:]\n",
    "            tide_load = fi[g+'/land_ice_segments/geophysical/tide_load'][:]\n",
    "            tide_ocean = fi[g+'/land_ice_segments/geophysical/tide_ocean'][:]\n",
    "            tide_pole = fi[g+'/land_ice_segments/geophysical/tide_pole'][:]\n",
    "            t_ref = fi['/ancillary_data/atlas_sdp_gps_epoch'][:]\n",
    "            rgt = fi['/orbit_info/rgt'][:] * np.ones(len(lat))\n",
    "            orb = np.full_like(h_li, k)\n",
    "\n",
    "        #---------------------------------------------#\n",
    "        # 2) Filter data according region and quality #\n",
    "        #---------------------------------------------#\n",
    "        \n",
    "        # Select a region of interest\n",
    "        if bbox:\n",
    "            lonmin, lonmax, latmin, latmax = bbox\n",
    "            bbox_mask = (lon >= lonmin) & (lon <= lonmax) & \\\n",
    "                        (lat >= latmin) & (lat <= latmax)\n",
    "        else:\n",
    "            bbox_mask = np.ones_like(lat, dtype=bool)  # get all\n",
    "            \n",
    "        # Only keep good data, and data inside bbox\n",
    "        mask = (q_flag == 0) & (np.abs(h_li) < 10e3) & (bbox_mask == 1)\n",
    "        \n",
    "        # Update variables\n",
    "        lat, lon, h_li, s_li, t_dt, h_rb, s_fg, snr, q_flag, f_sn, \\\n",
    "            tide_earth, tide_load, tide_ocean, tide_pole, dac, rgt, orb = \\\n",
    "                lat[mask], lon[mask], h_li[mask], s_li[mask], t_dt[mask], \\\n",
    "                h_rb[mask], s_fg[mask], snr[mask], q_flag[mask], f_sn[mask], \\\n",
    "                tide_earth[mask], tide_load[mask], tide_ocean[mask], \\\n",
    "                tide_pole[mask], dac[mask], rgt[mask], orb[mask]\n",
    "\n",
    "        # Test for no data\n",
    "        if len(h_li) == 0: continue\n",
    "\n",
    "        #-------------------------------------#\n",
    "        # 3) Convert time and separate tracks #\n",
    "        #-------------------------------------#\n",
    "        \n",
    "        # Time in GPS seconds (secs sinde 1980...)\n",
    "        t_gps = t_ref + t_dt\n",
    "\n",
    "        # Time in decimal years\n",
    "        t_year = gps2dyr(t_gps)\n",
    "\n",
    "        # Determine orbit type\n",
    "        i_asc, i_des = track_type(t_year, lat)\n",
    "        \n",
    "        #-----------------------#\n",
    "        # 4) Save selected data #\n",
    "        #-----------------------#\n",
    "        \n",
    "        # Define output file name\n",
    "        ofile = fname.replace('.h5', '_'+g[1:]+'.h5')\n",
    "                \n",
    "        # Save variables\n",
    "        with h5py.File(ofile, 'w') as f:\n",
    "            f['orbit'] = orb\n",
    "            f['lon'] = lon\n",
    "            f['lat'] = lat\n",
    "            f['h_elv'] = h_li\n",
    "            f['t_year'] = t_year\n",
    "            f['t_sec'] = t_gps\n",
    "            f['s_elv'] = s_li\n",
    "            f['h_rb'] = h_rb\n",
    "            f['s_fg'] = s_fg\n",
    "            f['snr'] = snr\n",
    "            f['q_flg'] = q_flag\n",
    "            f['f_sn'] = f_sn\n",
    "            f['tide_load'] = tide_load\n",
    "            f['tide_ocean'] = tide_ocean\n",
    "            f['tide_pole'] = tide_pole\n",
    "            f['tide_earth'] = tide_earth\n",
    "            f['dac'] = dac\n",
    "            f['rgt'] = rgt\n",
    "            f['trk_type'] = i_asc\n",
    "\n",
    "            print('out ->', ofile)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def read_atl03(fname, bbox=None):\n",
    "    print(fname)\n",
    "    \"\"\" \n",
    "    Read 1 ATL06 file and output 6 reduced files. \n",
    "    \n",
    "    Extract variables of interest and separate the ATL06 file \n",
    "    into each beam (ground track) and ascending/descending orbits.\n",
    "    \"\"\"\n",
    "    f = h5py.File(fname,'r')\n",
    "    print(f.keys())\n",
    "    # Each beam is a group\n",
    "    group = ['/gt1l', '/gt1r', '/gt2l', '/gt2r', '/gt3l', '/gt3r']\n",
    "    # Loop trough beams\n",
    "    for k,g in enumerate(group):\n",
    "    \n",
    "        #-----------------------------------#\n",
    "        # 1) Read in data for a single beam #\n",
    "        #-----------------------------------#\n",
    "    \n",
    "        # Load variables into memory (more can be added!)\n",
    "        with h5py.File(fname, 'r') as fi:\n",
    "            if g+'/heights' in fi.keys():\n",
    "                lat = fi[g+'/heights/lat_ph'][:]\n",
    "                lon = fi[g+'/heights/lon_ph'][:]\n",
    "                h = fi[g+'/heights/h_ph'][:]\n",
    "                conf = fi[g+'/heights/signal_conf_ph']\n",
    "                bkg = fi[g+'/bckgrd_atlas/bckgrd_counts'][:]\n",
    "\n",
    "                land_ice_class = conf[:,3]\n",
    "          \n",
    "        #-----------------------------------#\n",
    "        # 3) Filter data #\n",
    "        #-----------------------------------#\n",
    "                mask = (land_ice_class == 4) & (np.abs(h) < 10e3)\n",
    "                lat,lon,h = lat[mask],lon[mask],h[mask]\n",
    "        \n",
    "        #-----------------------#\n",
    "        # 4) Save selected data #\n",
    "        #-----------------------#\n",
    "        \n",
    "        # Define output file name\n",
    "                ofile = fname.replace('.h5', '_'+g[1:]+'.h5')\n",
    "                \n",
    "        # Save variables\n",
    "                with h5py.File(ofile, 'w') as f:\n",
    "                    f['lon'] = lon\n",
    "                    f['lat'] = lat\n",
    "                    f['h_elv'] = h\n",
    "                    f['bkc_ct'] = bkg\n",
    "            \n",
    "                    print('out ->', ofile)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "\n",
    "def list_files_local(path):\n",
    "    \"\"\" Get file list form local folder. \"\"\"\n",
    "    from glob import glob\n",
    "    return glob(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pwd\n",
    "# files = list_files_local('../data/RBIS/*ATL03*01.h5')\n",
    "\n",
    "\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20181202114602_09900112_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20181230213426_00370210_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20190111210924_02200210_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20181231102210_00450212_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20181214112102_11730112_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20190128201036_04790210_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20190112095707_02280212_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20181213223319_11650110_001_01.h5')]\n",
    "# del files[files.index('../data/RBIS/processed_ATL03_20190214082459_07310212_001_01.h5')]\n",
    "\n",
    "# njobs = 1#len(files)\n",
    "\n",
    "# #NOTE: Using Kamb bounding box for now\n",
    "# bbox = None #[-1124782, 81623, -919821, -96334]\n",
    "\n",
    "# if njobs == 1:\n",
    "#     print('running in serial ...')\n",
    "#     [read_atl03(f, bbox) for f in files]\n",
    "\n",
    "# else:\n",
    "#     print('running in parallel (%d jobs) ...' % njobs)\n",
    "#     from joblib import Parallel, delayed\n",
    "#     Parallel(n_jobs=njobs, verbose=5)(delayed(read_atl06)(f, bbox) for f in files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in serial ...\n",
      "../data/RLIS/processed_ATL03_20181224114725_13260112_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[2439 2655 2840 ...  776  846  815]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt1l.h5\n",
      "[2781 2815 2827 ... 1388 1429 1347]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt1r.h5\n",
      "[2912 2841 2792 ...  705  741  643]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt2l.h5\n",
      "[2594 2570 2614 ...  997 1007  958]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt2r.h5\n",
      "[2655 2706 2678 ...  933  896  940]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt3l.h5\n",
      "[3286 3213 3151 ... 1290 1197 1273]\n",
      "out -> ../data/RLIS/processed_ATL03_20181224114725_13260112_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190212091617_07010212_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "../data/RLIS/processed_ATL03_20181220115544_12650112_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[2431 2589 2596 ...  739  787  757]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt1l.h5\n",
      "[2840 2882 2874 ... 2120 2058 2134]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt1r.h5\n",
      "[2805 2629 2672 ...  351  340  350]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt2l.h5\n",
      "[2566 2518 2549 ... 2160 1975 2002]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt2r.h5\n",
      "[2455 2507 2499 ...  590  657  829]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt3l.h5\n",
      "[3038 3004 2940 ... 2244 2187 2242]\n",
      "out -> ../data/RLIS/processed_ATL03_20181220115544_12650112_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190125212731_04340210_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[   1    3    0 ... 1192 1139 1094]\n",
      "out -> ../data/RLIS/processed_ATL03_20190125212731_04340210_001_01_gt1l.h5\n",
      "[  2   0   0 ... 677 679 695]\n",
      "out -> ../data/RLIS/processed_ATL03_20190125212731_04340210_001_01_gt1r.h5\n",
      "../data/RLIS/processed_ATL03_20181223225942_13180110_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[ 26  22  15 ... 861 801 907]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt1l.h5\n",
      "[  93   83  126 ... 1188 1294 1238]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt1r.h5\n",
      "[ 23  18  17 ... 691 664 659]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt2l.h5\n",
      "[ 67  84  96 ... 793 827 775]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt2r.h5\n",
      "[ 36  32  32 ... 600 592 608]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt3l.h5\n",
      "[ 142  100  122 ... 1075 1031 1034]\n",
      "out -> ../data/RLIS/processed_ATL03_20181223225942_13180110_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190121213546_03730210_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[   0    0    0 ... 1156 1094 1155]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt1l.h5\n",
      "[ 23  20  18 ... 677 619 703]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt1r.h5\n",
      "[ 54  53  45 ... 923 948 969]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt2l.h5\n",
      "[ 16  26  11 ... 759 712 743]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt2r.h5\n",
      "[   1    0    2 ... 1149 1110 1083]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt3l.h5\n",
      "[ 25  22  21 ... 792 726 759]\n",
      "out -> ../data/RLIS/processed_ATL03_20190121213546_03730210_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190117214358_03120210_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[  61   90   77 ... 1163 1237 1180]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt1l.h5\n",
      "[  0   4   5 ... 755 732 744]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt1r.h5\n",
      "[ 63  51  56 ... 990 999 951]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt2l.h5\n",
      "[  2   1   2 ... 829 804 854]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt2r.h5\n",
      "[  72   88   63 ... 1137 1157 1135]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt3l.h5\n",
      "[  1   2   3 ... 768 840 802]\n",
      "out -> ../data/RLIS/processed_ATL03_20190117214358_03120210_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190215202015_07540210_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[   0    3    0 ... 2148 2192 2091]\n",
      "out -> ../data/RLIS/processed_ATL03_20190215202015_07540210_001_01_gt2l.h5\n",
      "[   6    5   12 ... 2236 2278 2177]\n",
      "out -> ../data/RLIS/processed_ATL03_20190215202015_07540210_001_01_gt2r.h5\n",
      "[   1    0    1 ... 2537 2537 2636]\n",
      "out -> ../data/RLIS/processed_ATL03_20190215202015_07540210_001_01_gt3l.h5\n",
      "[   5   11   10 ... 2243 2231 2218]\n",
      "out -> ../data/RLIS/processed_ATL03_20190215202015_07540210_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190126101515_04420212_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "../data/RLIS/processed_ATL03_20190113215221_02510210_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "../data/RLIS/processed_ATL03_20190114104003_02590212_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[2978 2840 2892 ...  630  637  547]\n",
      "out -> ../data/RLIS/processed_ATL03_20190114104003_02590212_001_01_gt1l.h5\n",
      "[2322 2315 2336 ...  383  361  438]\n",
      "out -> ../data/RLIS/processed_ATL03_20190114104003_02590212_001_01_gt1r.h5\n",
      "[2311 2284 2307 ...  295  285  291]\n",
      "out -> ../data/RLIS/processed_ATL03_20190114104003_02590212_001_01_gt2l.h5\n",
      "[2373 2320 2299 ...  407  389  438]\n",
      "out -> ../data/RLIS/processed_ATL03_20190114104003_02590212_001_01_gt2r.h5\n",
      "../data/RLIS/processed_ATL03_20181219230801_12570110_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[ 30  36  32 ... 843 831 854]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt1l.h5\n",
      "[ 124  115  112 ... 1239 1212 1158]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt1r.h5\n",
      "[ 46  25  34 ... 923 917 901]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt2l.h5\n",
      "[  73   66   85 ... 1053 1070 1090]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt2r.h5\n",
      "[ 22  21  18 ... 899 877 848]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt3l.h5\n",
      "[  94  100  111 ... 1338 1264 1274]\n",
      "out -> ../data/RLIS/processed_ATL03_20181219230801_12570110_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190122102329_03810212_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[2722 2726 2756 ... 1641 1653 1765]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt1l.h5\n",
      "[2209 2179 2080 ...  622  656  724]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt1r.h5\n",
      "[2215 2129 2136 ... 1746 1697 1805]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt2l.h5\n",
      "[2231 2302 2307 ... 1004  962  961]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt2r.h5\n",
      "[2772 2725 2740 ... 2252 2245 2208]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt3l.h5\n",
      "[2332 2384 2419 ... 1057 1077 1132]\n",
      "out -> ../data/RLIS/processed_ATL03_20190122102329_03810212_001_01_gt3r.h5\n",
      "../data/RLIS/processed_ATL03_20190118103142_03200212_001_01.h5\n",
      "<KeysViewHDF5 ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']>\n",
      "[2703 2859 2708 ...  383  305  327]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt1l.h5\n",
      "[2176 2173 2346 ...  322  320  335]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt1r.h5\n",
      "[2167 2174 2137 ...  276  296  327]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt2l.h5\n",
      "[2407 2299 2291 ...  236  249  223]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt2r.h5\n",
      "[2631 2677 2559 ...  335  342  311]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt3l.h5\n",
      "[2388 2370 2378 ...  227  230  235]\n",
      "out -> ../data/RLIS/processed_ATL03_20190118103142_03200212_001_01_gt3r.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!pwd\n",
    "files = list_files_local('../data/RLIS/*ATL03*01.h5')\n",
    "\n",
    "#print(files)\n",
    "\n",
    "njobs = 1#len(files)\n",
    "\n",
    "#NOTE: Using Kamb bounding box for now\n",
    "bbox = None #[-1124782, 81623, -919821, -96334]\n",
    "\n",
    "if njobs == 1:\n",
    "    print('running in serial ...')\n",
    "    [read_atl03(f, bbox) for f in files]\n",
    "\n",
    "else:\n",
    "    print('running in parallel (%d jobs) ...' % njobs)\n",
    "    from joblib import Parallel, delayed\n",
    "    Parallel(n_jobs=njobs, verbose=5)(delayed(read_atl06)(f, bbox) for f in files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131554,) (131554,) (85044,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc7d226ec4f418bb16e0b7cfe3e54a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0be8260550>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "def read_h5(fname, vnames=[]):\n",
    "    \"\"\" Simple HDF5 reader. \"\"\"\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        return [f[v][:] for v in vnames]\n",
    "\n",
    "    \n",
    "files = list_files_local('../data/RLIS/*ATL03*gt*')\n",
    "\n",
    "#33\n",
    "#2\n",
    "#6\n",
    "#18\n",
    "#23\n",
    "#54\n",
    "\n",
    "\n",
    "lon, lat, h,bkg = read_h5(files[54], ['lon', 'lat', 'h_elv','bkc_ct'])\n",
    "print(lon.shape,h.shape,bkg.shape)\n",
    "\n",
    "plt.plot(bkg)\n",
    "# x_ice, y_ice = transform_coord(4326, 3031, lon, lat)\n",
    " \n",
    "# plt.figure()\n",
    "# plt.plot(h,'.',markersize = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_bands = glob(\"*.TIF\")\n",
    "image1_bands.sort()\n",
    "\n",
    "image1_blue = np.squeeze(rio.open(image1_bands[0]).read())\n",
    "image1_red = np.squeeze(rio.open(image1_bands[2]).read())\n",
    "image1_green = np.squeeze(rio.open(image1_bands[1]).read())\n",
    "\n",
    "image2_blue = np.squeeze(rio.open(image1_bands[3]).read())\n",
    "image2_red = np.squeeze(rio.open(image1_bands[5]).read())\n",
    "image2_green = np.squeeze(rio.open(image1_bands[4]).read())\n",
    "\n",
    "#image1_nir = np.squeeze(rio.open(image1_bands[3]).read())\n",
    "    \n",
    "#Normalize bands into 0.0 - 1.0 scale\n",
    "def normalize(array):\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "\n",
    "# Normalize band DN\n",
    "blue = normalize(image1_blue)\n",
    "red = normalize(image1_red)\n",
    "green = normalize(image1_green)\n",
    "#nir = normalize(image1_nir)\n",
    "\n",
    "#ndwi = (green - nir)/(green - nir)\n",
    "# Stack bands\n",
    "rgb = np.dstack((red, green, blue))\n",
    "#print(nrg.shape())\n",
    "# View the color composite\n",
    "rgb = rgb.astype(float)\n",
    "#plt.imshow(rgb)\n",
    "#es.plot_bands(image1_blue[0],title=\"Landsat Cropped Band 4\\nColdsprings Fire Scar\",cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9161, 9181, 3)\n"
     ]
    }
   ],
   "source": [
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster and metadata\n",
    "tile_path = 'LC08_L1GT_167109_20190125_20190205_01_T2_B2.TIF'\n",
    "Raster = gdal.Open(tile_path)\n",
    "width = Raster.RasterXSize\n",
    "height = Raster.RasterYSize\n",
    "gt = Raster.GetGeoTransform()\n",
    "array = Raster.ReadAsArray()\n",
    "\n",
    "# Pixel numbers\n",
    "x = np.arange(0, width)\n",
    "y = np.arange(0, height)\n",
    "\n",
    "# Grid Cell Coordinates of upper left corner in EPSG:3031 UTM. \n",
    "X = gt[0] + x * gt[1] \n",
    "Y = gt[3] + y * gt[5]\n",
    "\n",
    "#xx,yy = np.meshgrid(X,Y)\n",
    "\n",
    "#lon, lat = transform_coord(3031, 4326, xx, yy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-04079225d156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# f, ax = plt.subplots(1, figsize=(12, 6))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# world.plot(ax=ax, facecolor='lightgray', edgecolor='gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# # Load \"Natural Earth‚Äù countries dataset, bundled with GeoPandas\n",
    "# world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# # Overlay glacier outline\n",
    "# f, ax = plt.subplots(1, figsize=(12, 6))\n",
    "# world.plot(ax=ax, facecolor='lightgray', edgecolor='gray')\n",
    "plt.figure()\n",
    "plt.imshow(rgb, extent = [np.min(X), np.max(X), np.min(Y), np.max(Y)])\n",
    "plt.plot(x_ice, y_ice,'r')\n",
    "# ax.set_ylim([-71.5, -67.5])\n",
    "# ax.set_xlim([7.5,15.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
